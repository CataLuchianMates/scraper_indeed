{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download ChromeDriver from link: http://chromedriver.chromium.org/downloads\n",
    "#Save it in the same folder as the python script\n",
    "driver = webdriver.Chrome(\"./chromedriver\")\n",
    "\n",
    "dataFrame = pd.DataFrame(columns=[\"Title\",\"Location\",\"Company\",\"Rating\",\"Salary\",\"Sponsored\",\"Date\",\"As of Date\", \"Description\"])\n",
    "\n",
    "\n",
    "for i in range (0,5000,20):\n",
    "\n",
    "    ##Step1: Get the page\n",
    "    driver.get(\"https://www.indeed.ca/jobs?q=hospitality&l=Canada&start=\"+str(i))\n",
    "    driver.maximize_window()\n",
    "    driver.implicitly_wait(4)\n",
    "\n",
    "    all_jobs = driver.find_elements_by_class_name('result')\n",
    "\n",
    "    for job in all_jobs:\n",
    "        result_html = job.get_attribute('innerHTML')\n",
    "        soup = BeautifulSoup(result_html, 'html.parser')\n",
    "\n",
    "        try:\n",
    "            title = soup.find(\"a\", class_=\"jobtitle\").text.replace('\\n', '')\n",
    "        except:\n",
    "            title = 'None'\n",
    "\n",
    "        try:\n",
    "            company = soup.find(class_=\"company\").text.replace('\\n', \"\").strip()\n",
    "        except:\n",
    "            company = 'None'\n",
    "            \n",
    "        try:\n",
    "            rating = soup.find(class_=\"ratingsContent\").text.replace('\\n', \"\").strip()\n",
    "        except:\n",
    "            rating = 'None'\n",
    "\n",
    "        try:\n",
    "            location = soup.find(class_=\"location\")\n",
    "        except:\n",
    "            location = 'None'\n",
    "\n",
    "        try:\n",
    "            salary = soup.find(class_=\"salary\").text.replace('\\n', \"\").strip()\n",
    "        except:\n",
    "            salary = 'None'\n",
    "\n",
    "        try:\n",
    "            sponsored = soup.find(class_=\"sponsoredGray\").text\n",
    "            #sponsored = \"Sponsored\"\n",
    "        except:\n",
    "            sponsored = 'None'\n",
    "            \n",
    "        try:\n",
    "            date = soup.find(class_=\"date\").text.replace('\\n', \"\").strip()\n",
    "        except:\n",
    "            date = 'None'\n",
    "\n",
    "        \n",
    "        sum_div = job.find_elements_by_class_name(\"summary\")[0]\n",
    "        \n",
    "        try:\n",
    "            sum_div.click()\n",
    "        except:\n",
    "            close_button=driver.find_element_by_class_name('popover-x-button-close')\n",
    "            close_button.click()\n",
    "            sum_div.click()\n",
    "\n",
    "        today = datetime.today().strftime('%Y-%m-%d')  \n",
    "        \n",
    "        try:\n",
    "            job_desc = driver.find_element_by_id('vjs-desc').text\n",
    "        except:\n",
    "            job_desc = 'None'\n",
    "\n",
    "        dataFrame = dataFrame.append({'Title': title, 'Location':location, 'Company':company, 'Rating': rating,\n",
    "                                      'Salary':salary, 'Sponsored':sponsored, 'Date':date,'As of Date':today,  \n",
    "                                      'Description':job_desc}, \n",
    "        ignore_index = True)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3737, 9)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame_noduplicates = dataFrame.drop_duplicates()\n",
    "dataFrame_noduplicates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame_noduplicates.to_csv(\"environmental_canada_april30_5000.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
